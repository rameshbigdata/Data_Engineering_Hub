{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b2aacbf-37c7-4341-82a6-1be2cd0f6a50",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Broadcast variables in Databricks (Apache Spark) are used to efficiently distribute read-only variables to worker nodes, reducing communication costs during task execution. Understanding when and how to use broadcast variables can significantly impact performance, especially when dealing with large datasets or frequent joins.\n",
    "\n",
    "Broadcast Variable Usage\n",
    "\n",
    "Without Broadcast Variable\n",
    "\n",
    "When you perform operations without using broadcast variables, Spark may shuffle data across the network multiple times, which can lead to increased network overhead and slower performance. For instance, consider the following example without using a broadcast variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49b4f906-7aaa-4791-a3f4-b4b5ced4c751",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th></tr></thead><tbody><tr><td>2</td></tr><tr><td>3</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         2
        ],
        [
         3
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"Broadcast Variable Example\").getOrCreate()\n",
    "\n",
    "# Sample large DataFrame\n",
    "large_df = spark.range(100)\n",
    "\n",
    "# Broadcast variable example\n",
    "broadcast_var = spark.sparkContext.broadcast([1, 2, 3, 4, 5])\n",
    "\n",
    "# Function to filter data using broadcast variable\n",
    "def filter_data(value):\n",
    "    return value in broadcast_var.value\n",
    "\n",
    "# Apply filter operation without broadcast variable\n",
    "filtered_data = large_df.filter((large_df[\"id\"]>1) & (large_df[\"id\"]<4)).display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea058a50-9423-496f-9a2b-f2020fecc16c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "With Broadcast Variable:\n",
    "\n",
    "Using a broadcast variable optimizes performance by distributing the variable to worker nodes only once, thereby reducing network traffic and improving execution speed. Hereâ€™s how you can modify the previous example to use a broadcast variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d904c667-09a3-4746-8f8a-6f70b43fa196",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th></tr></thead><tbody><tr><td>1</td></tr><tr><td>2</td></tr><tr><td>3</td></tr><tr><td>4</td></tr><tr><td>5</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1
        ],
        [
         2
        ],
        [
         3
        ],
        [
         4
        ],
        [
         5
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import BooleanType\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"Broadcast Variable Example\").getOrCreate()\n",
    "\n",
    "# Sample large DataFrame\n",
    "large_df = spark.range(100)\n",
    "\n",
    "# Broadcast variable example\n",
    "broadcast_var = spark.sparkContext.broadcast([1, 2, 3, 4, 5])\n",
    "\n",
    "# Function to filter data using broadcast variable\n",
    "def filter_data(value):\n",
    "    return value in broadcast_var.value\n",
    "\n",
    "# Register UDF\n",
    "filter_data_udf = udf(filter_data, BooleanType())\n",
    "\n",
    "# Apply filter operation with broadcast variable\n",
    "filtered_data = large_df.filter(filter_data_udf(col(\"id\")))\n",
    "filtered_data.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e24a8af0-8f7a-4780-b0d8-9038e7732885",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Performance Impact\n",
    "Without Broadcast Variable: Spark may shuffle data across the network multiple times, especially during operations like joins or filters involving large datasets, leading to higher network overhead and slower performance.\n",
    "\n",
    "With Broadcast Variable: The broadcast variable is sent to each executor once and reused across multiple tasks, reducing the amount of data shuffled over the network and improving overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eedc82d3-0497-4f8a-a6e0-d0d3c888c914",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>value</th></tr></thead><tbody><tr><td>1</td><td>A</td></tr><tr><td>2</td><td>B</td></tr><tr><td>3</td><td>C</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "A"
        ],
        [
         2,
         "B"
        ],
        [
         3,
         "C"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "value",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"Broadcast Join Example\").getOrCreate()\n",
    "\n",
    "# Sample small DataFrame\n",
    "small_df = spark.createDataFrame([(1, \"A\"), (2, \"B\"), (3, \"C\")], [\"id\", \"value\"])\n",
    "\n",
    "# Sample large DataFrame\n",
    "large_df = spark.range(1000).toDF(\"id\")\n",
    "\n",
    "# Perform broadcast join\n",
    "joined_df = large_df.join(broadcast(small_df), \"id\")\n",
    "\n",
    "# Show the results\n",
    "joined_df.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db836cb4-dc61-4354-878e-c41b0fc13abc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Guidelines for Using Broadcast Variables\n",
    "\n",
    "Size Consideration: Use broadcast variables for read-only data that is small enough to fit in memory across all worker nodes. This typically includes lookup tables or small datasets used in joins or filters.\n",
    "\n",
    "Optimal Use Cases: Broadcast variables are particularly effective when used with operations like joins (broadcastHashJoin) or when filtering large DataFrames based on a small set of values.\n",
    "\n",
    "Broadcast Joins: When performing joins, consider broadcasting smaller DataFrames to optimize performance, especially when joining large and small DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29af0a74-6a26-48ae-a4ee-296afbdb8e00",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Conclusion:\n",
    "\n",
    "Broadcast variables in Databricks (Apache Spark) are a powerful optimization technique for reducing network overhead and improving performance, especially when dealing with large datasets and frequent data accesses. By leveraging broadcast variables judiciously, you can significantly enhance the efficiency of your Spark jobs on Databricks."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Databricks | Spark | Broadcast Variable with and without.",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
