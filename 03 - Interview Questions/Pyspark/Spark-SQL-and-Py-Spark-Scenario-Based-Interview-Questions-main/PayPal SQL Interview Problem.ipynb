{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53f8b328-a54c-44b9-9449-67d36455c820",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Problem Statement\n",
    "The question goes as follows we need to obtain the list of departments and average lower the overall average salary of the company a member when calculating the companies average salary you must include the salaries of the department you are comparing with it for instance when comparing the  average salary of the which department with the companies average the HR department salary shouldn't be taken into considerations for the calculation of the company average salary likewise if you want to compare the average salary of the Finance Department with the companies average the companies average salary should not include the salaries of the finance department and show on essentially the companies average salary will be dynamic for each department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b05549ee-4445-4436-8704-01838ac9da46",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>emp_id</th><th>emp_name</th><th>department_id</th><th>salary</th><th>manager_id</th><th>emp_age</th></tr></thead><tbody><tr><td>1</td><td>Ankit</td><td>100</td><td>10000</td><td>4</td><td>39</td></tr><tr><td>2</td><td>Mohit</td><td>100</td><td>15000</td><td>5</td><td>48</td></tr><tr><td>3</td><td>Vikas</td><td>100</td><td>10000</td><td>4</td><td>37</td></tr><tr><td>4</td><td>Rohit</td><td>100</td><td>5000</td><td>2</td><td>16</td></tr><tr><td>5</td><td>Mudit</td><td>200</td><td>12000</td><td>6</td><td>55</td></tr><tr><td>6</td><td>Agam</td><td>200</td><td>12000</td><td>2</td><td>14</td></tr><tr><td>7</td><td>Sanjay</td><td>200</td><td>9000</td><td>2</td><td>13</td></tr><tr><td>8</td><td>Ashish</td><td>200</td><td>5000</td><td>2</td><td>12</td></tr><tr><td>9</td><td>Mukesh</td><td>300</td><td>6000</td><td>6</td><td>51</td></tr><tr><td>10</td><td>Rakesh</td><td>300</td><td>7000</td><td>6</td><td>50</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Ankit",
         100,
         10000,
         4,
         39
        ],
        [
         2,
         "Mohit",
         100,
         15000,
         5,
         48
        ],
        [
         3,
         "Vikas",
         100,
         10000,
         4,
         37
        ],
        [
         4,
         "Rohit",
         100,
         5000,
         2,
         16
        ],
        [
         5,
         "Mudit",
         200,
         12000,
         6,
         55
        ],
        [
         6,
         "Agam",
         200,
         12000,
         2,
         14
        ],
        [
         7,
         "Sanjay",
         200,
         9000,
         2,
         13
        ],
        [
         8,
         "Ashish",
         200,
         5000,
         2,
         12
        ],
        [
         9,
         "Mukesh",
         300,
         6000,
         6,
         51
        ],
        [
         10,
         "Rakesh",
         300,
         7000,
         6,
         50
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "emp_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "emp_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "department_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "manager_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "emp_age",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import nessesary functions\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"emp_id\", IntegerType(), nullable=False),\n",
    "    StructField(\"emp_name\", StringType(), nullable=False),\n",
    "    StructField(\"department_id\", IntegerType(), nullable=False),\n",
    "    StructField(\"salary\", IntegerType(), nullable=False),\n",
    "    StructField(\"manager_id\", IntegerType(), nullable=False),\n",
    "    StructField(\"emp_age\", IntegerType(), nullable=False)\n",
    "])\n",
    "# Create data\n",
    "data = [\n",
    "    (1, 'Ankit', 100, 10000, 4, 39),\n",
    "    (2, 'Mohit', 100, 15000, 5, 48),\n",
    "    (3, 'Vikas', 100, 10000, 4, 37),\n",
    "    (4, 'Rohit', 100, 5000, 2, 16),\n",
    "    (5, 'Mudit', 200, 12000, 6, 55),\n",
    "    (6, 'Agam', 200, 12000, 2, 14),\n",
    "    (7, 'Sanjay', 200, 9000, 2, 13),\n",
    "    (8, 'Ashish', 200, 5000, 2, 12),\n",
    "    (9, 'Mukesh', 300, 6000, 6, 51),\n",
    "    (10, 'Rakesh', 300, 7000, 6, 50)\n",
    "]\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema)\n",
    "# Show DataFrame\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8709b3e6-381e-43a7-8c19-86e6979e8e10",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------+------+----------+-------+\n|emp_id|emp_name|department_id|salary|manager_id|emp_age|\n+------+--------+-------------+------+----------+-------+\n|     1|   Ankit|          100| 10000|         4|     39|\n|     2|   Mohit|          100| 15000|         5|     48|\n|     3|   Vikas|          100| 10000|         4|     37|\n|     4|   Rohit|          100|  5000|         2|     16|\n|     5|   Mudit|          200| 12000|         6|     55|\n|     6|    Agam|          200| 12000|         2|     14|\n|     7|  Sanjay|          200|  9000|         2|     13|\n|     8|  Ashish|          200|  5000|         2|     12|\n|     9|  Mukesh|          300|  6000|         6|     51|\n|    10|  Rakesh|          300|  7000|         6|     50|\n+------+--------+-------------+------+----------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# Save DataFrame as a table (in-memory or Hive table if using Hive)\n",
    "# To save as an in-memory table\n",
    "df.createOrReplaceTempView(\"emp\")\n",
    "# To save as a Hive table (ensure Hive support is enabled in Spark)\n",
    "df.write.saveAsTable(\"emp\")\n",
    "# Now you can run SQL queries on the \"emp\" table\n",
    "spark.sql(\"SELECT * FROM emp\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59d0691c-74c1-4075-82f6-6c150e2ef667",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>department_id</th><th>dept_avg_salary</th><th>dynamic_company_avg_salary</th></tr></thead><tbody><tr><td>300</td><td>6500.0</td><td>9750.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         300,
         6500.0,
         9750.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "department_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "dept_avg_salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "dynamic_company_avg_salary",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, avg, sum as spark_sum, count\n",
    "# Calculate total company salary and employee count\n",
    "total_salary = df.agg(spark_sum(col(\"salary\")).alias(\"total_salary\")).collect()[0][\"total_salary\"]\n",
    "total_count = df.agg(count(\"*\").alias(\"total_count\")).collect()[0][\"total_count\"]\n",
    "\n",
    "# Calculate average salary for each department\n",
    "dept_avg_salary_df = df.groupBy(\"department_id\").agg(\n",
    "    avg(\"salary\").alias(\"dept_avg_salary\"),\n",
    "    spark_sum(\"salary\").alias(\"dept_total_salary\"),\n",
    "    count(\"emp_id\").alias(\"dept_employee_count\")\n",
    ")\n",
    "\n",
    "# Calculate dynamic company average salary for each department\n",
    "result_df = dept_avg_salary_df.withColumn(\n",
    "    \"dynamic_company_avg_salary\",\n",
    "    (total_salary - col(\"dept_total_salary\")) / (total_count - col(\"dept_employee_count\"))\n",
    ").filter(col(\"dept_avg_salary\") < col(\"dynamic_company_avg_salary\"))\n",
    "\n",
    "# Show the result\n",
    "result=result_df.select(\"department_id\", \"dept_avg_salary\", \"dynamic_company_avg_salary\")\n",
    "result.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4efe2cf-3786-49d1-abdd-d86adf82d261",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>department_id</th><th>dept_avg_salary</th><th>dynamic_company_avg_salary</th></tr></thead><tbody><tr><td>300</td><td>6500.0</td><td>9750.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         300,
         6500.0,
         9750.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "department_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "dept_avg_salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "dynamic_company_avg_salary",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Calculate the average salary for each department\n",
    "WITH dept_avg_salary AS (\n",
    "    SELECT\n",
    "        department_id,\n",
    "        AVG(salary) AS dept_avg_salary,\n",
    "        SUM(salary) AS dept_total_salary,\n",
    "        COUNT(emp_id) AS dept_employee_count\n",
    "    FROM emp\n",
    "    GROUP BY department_id\n",
    "),\n",
    "-- Calculate the total company salary and total employee count\n",
    "company_totals AS (\n",
    "    SELECT\n",
    "        SUM(salary) AS total_salary,\n",
    "        COUNT(emp_id) AS total_count\n",
    "    FROM emp\n",
    "),\n",
    "-- Calculate the dynamic company average salary for each department\n",
    "dynamic_company_avg_salary AS (\n",
    "    SELECT\n",
    "        d.department_id,\n",
    "        d.dept_avg_salary,\n",
    "        (c.total_salary - d.dept_total_salary) / (c.total_count - d.dept_employee_count) AS dynamic_company_avg_salary\n",
    "    FROM\n",
    "        dept_avg_salary d,\n",
    "        company_totals c\n",
    ")\n",
    "-- Compare and select departments with average salaries lower than the dynamic company average salary\n",
    "SELECT\n",
    "    department_id,\n",
    "    dept_avg_salary,\n",
    "    dynamic_company_avg_salary\n",
    "FROM\n",
    "    dynamic_company_avg_salary\n",
    "WHERE\n",
    "    dept_avg_salary < dynamic_company_avg_salary;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 703053975603368,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "PayPal SQL Interview Problem",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
