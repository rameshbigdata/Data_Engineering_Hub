{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2bbd1a45-6357-4252-b506-faf2ab7eec4b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Repartition vs Coalesce\n",
    "In Databricks and Spark, optimizing performance often involves efficient data partitioning. Two common operations for managing partitions are repartition and coalesce. Both of these methods are used to adjust the number of partitions in a DataFrame, but they serve different purposes and have different performance implications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "187b28a3-0000-4f5b-aea8-6baf77383cbe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Repartition vs. Coalesce\n",
    "\n",
    "###Repartition\n",
    "\n",
    "\n",
    "Purpose: Increase or decrease the number of partitions.\n",
    "Shuffling: Causes a full shuffle of data across the cluster, which can be expensive.\n",
    "Use Case: Best used when increasing the number of partitions or when the target number of partitions is significantly different from the current number.\n",
    "\n",
    "Syntax: df.repartition(num_partitions)\n",
    "\n",
    "###Coalesce\n",
    "\n",
    "\n",
    "Purpose: Reduce the number of partitions.\n",
    "Shuffling: Avoids full shuffle by combining existing partitions into fewer partitions.\n",
    "Use Case: Best used for reducing the number of partitions, particularly when the new number of partitions is smaller but not drastically different from the current number.\n",
    "\n",
    "Syntax: df.coalesce(num_partitions)\n",
    "Performance Implications\n",
    "Repartition: Because it involves a full shuffle of the data, repartition can be resource-intensive and time-consuming. It's more suitable when the data distribution needs to be significantly altered or when you need to increase the number of partitions to distribute the load more evenly across the cluster.\n",
    "\n",
    "Coalesce: Since it avoids a full shuffle by combining partitions, coalesce is more efficient for reducing the number of partitions. It's less expensive and faster compared to repartition, making it ideal for scenarios where you want to optimize performance by reducing the number of partitions without significantly changing the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "141d224a-7115-4e53-92d1-40f1f451c6c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th></tr></thead><tbody><tr><td>3</td></tr><tr><td>1</td></tr><tr><td>23</td></tr><tr><td>28</td></tr><tr><td>27</td></tr><tr><td>38</td></tr><tr><td>47</td></tr><tr><td>51</td></tr><tr><td>73</td></tr><tr><td>76</td></tr><tr><td>93</td></tr><tr><td>7</td></tr><tr><td>16</td></tr><tr><td>33</td></tr><tr><td>49</td></tr><tr><td>56</td></tr><tr><td>64</td></tr><tr><td>86</td></tr><tr><td>77</td></tr><tr><td>95</td></tr><tr><td>99</td></tr><tr><td>0</td></tr><tr><td>21</td></tr><tr><td>35</td></tr><tr><td>44</td></tr><tr><td>53</td></tr><tr><td>70</td></tr><tr><td>85</td></tr><tr><td>81</td></tr><tr><td>90</td></tr><tr><td>96</td></tr><tr><td>10</td></tr><tr><td>18</td></tr><tr><td>25</td></tr><tr><td>39</td></tr><tr><td>57</td></tr><tr><td>68</td></tr><tr><td>79</td></tr><tr><td>87</td></tr><tr><td>89</td></tr><tr><td>5</td></tr><tr><td>19</td></tr><tr><td>24</td></tr><tr><td>31</td></tr><tr><td>37</td></tr><tr><td>52</td></tr><tr><td>58</td></tr><tr><td>62</td></tr><tr><td>75</td></tr><tr><td>97</td></tr><tr><td>6</td></tr><tr><td>22</td></tr><tr><td>12</td></tr><tr><td>30</td></tr><tr><td>42</td></tr><tr><td>61</td></tr><tr><td>59</td></tr><tr><td>72</td></tr><tr><td>84</td></tr><tr><td>98</td></tr><tr><td>8</td></tr><tr><td>14</td></tr><tr><td>17</td></tr><tr><td>32</td></tr><tr><td>45</td></tr><tr><td>60</td></tr><tr><td>67</td></tr><tr><td>63</td></tr><tr><td>83</td></tr><tr><td>91</td></tr><tr><td>2</td></tr><tr><td>20</td></tr><tr><td>34</td></tr><tr><td>41</td></tr><tr><td>50</td></tr><tr><td>66</td></tr><tr><td>71</td></tr><tr><td>80</td></tr><tr><td>94</td></tr><tr><td>9</td></tr><tr><td>13</td></tr><tr><td>36</td></tr><tr><td>43</td></tr><tr><td>40</td></tr><tr><td>54</td></tr><tr><td>65</td></tr><tr><td>69</td></tr><tr><td>82</td></tr><tr><td>88</td></tr><tr><td>11</td></tr><tr><td>4</td></tr><tr><td>15</td></tr><tr><td>26</td></tr><tr><td>29</td></tr><tr><td>46</td></tr><tr><td>48</td></tr><tr><td>55</td></tr><tr><td>74</td></tr><tr><td>78</td></tr><tr><td>92</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         3
        ],
        [
         1
        ],
        [
         23
        ],
        [
         28
        ],
        [
         27
        ],
        [
         38
        ],
        [
         47
        ],
        [
         51
        ],
        [
         73
        ],
        [
         76
        ],
        [
         93
        ],
        [
         7
        ],
        [
         16
        ],
        [
         33
        ],
        [
         49
        ],
        [
         56
        ],
        [
         64
        ],
        [
         86
        ],
        [
         77
        ],
        [
         95
        ],
        [
         99
        ],
        [
         0
        ],
        [
         21
        ],
        [
         35
        ],
        [
         44
        ],
        [
         53
        ],
        [
         70
        ],
        [
         85
        ],
        [
         81
        ],
        [
         90
        ],
        [
         96
        ],
        [
         10
        ],
        [
         18
        ],
        [
         25
        ],
        [
         39
        ],
        [
         57
        ],
        [
         68
        ],
        [
         79
        ],
        [
         87
        ],
        [
         89
        ],
        [
         5
        ],
        [
         19
        ],
        [
         24
        ],
        [
         31
        ],
        [
         37
        ],
        [
         52
        ],
        [
         58
        ],
        [
         62
        ],
        [
         75
        ],
        [
         97
        ],
        [
         6
        ],
        [
         22
        ],
        [
         12
        ],
        [
         30
        ],
        [
         42
        ],
        [
         61
        ],
        [
         59
        ],
        [
         72
        ],
        [
         84
        ],
        [
         98
        ],
        [
         8
        ],
        [
         14
        ],
        [
         17
        ],
        [
         32
        ],
        [
         45
        ],
        [
         60
        ],
        [
         67
        ],
        [
         63
        ],
        [
         83
        ],
        [
         91
        ],
        [
         2
        ],
        [
         20
        ],
        [
         34
        ],
        [
         41
        ],
        [
         50
        ],
        [
         66
        ],
        [
         71
        ],
        [
         80
        ],
        [
         94
        ],
        [
         9
        ],
        [
         13
        ],
        [
         36
        ],
        [
         43
        ],
        [
         40
        ],
        [
         54
        ],
        [
         65
        ],
        [
         69
        ],
        [
         82
        ],
        [
         88
        ],
        [
         11
        ],
        [
         4
        ],
        [
         15
        ],
        [
         26
        ],
        [
         29
        ],
        [
         46
        ],
        [
         48
        ],
        [
         55
        ],
        [
         74
        ],
        [
         78
        ],
        [
         92
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"Partition Optimization\").getOrCreate()\n",
    "\n",
    "# Sample DataFrame with 100 partitions\n",
    "df = spark.range(0, 100, 1).repartition(10)\n",
    "\n",
    "df.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d20aa9e-1d4f-4dad-b888-aa5ca3114f5b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions after repartition:  20\n"
     ]
    }
   ],
   "source": [
    "# Repartition to 200 partitions (full shuffle)\n",
    "df_repartitioned = df.repartition(20)\n",
    "\n",
    "# Show the number of partitions\n",
    "print(\"Number of partitions after repartition: \", df_repartitioned.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "378f375d-34dd-457c-9548-b56980a1649f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions after coalesce:  5\n"
     ]
    }
   ],
   "source": [
    "# Coalesce to 50 partitions (avoids full shuffle)\n",
    "df_coalesced = df.coalesce(5)\n",
    "\n",
    "# Show the number of partitions\n",
    "print(\"Number of partitions after coalesce: \", df_coalesced.rdd.getNumPartitions())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c205b563-3a4b-4108-a338-2faad9520ff7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Observations\n",
    "Repartitioning to 20 partitions: This will cause a full shuffle, which can be expensive but necessary if you need to balance the load more evenly across the cluster.\n",
    "Coalescing to 5 partitions: This avoids a full shuffle and is more efficient, making it suitable for reducing the number of partitions, especially when preparing the data for downstream actions like writing to disk.\n",
    "Conclusion\n",
    "Choosing between repartition and coalesce depends on your specific use case:\n",
    "\n",
    "Use repartition when you need to significantly change the number of partitions, particularly to increase them.\n",
    "Use coalesce when you need to reduce the number of partitions without incurring the cost of a full shuffle.\n",
    "Understanding and appropriately using these methods can lead to significant performance improvements in your Spark jobs on Databricks."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Databricks| Spark | Performance Optimization",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
